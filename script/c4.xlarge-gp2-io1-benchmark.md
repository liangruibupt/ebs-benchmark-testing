# c4.xlarge EBS Snapshot testing

问题思考：对于一个100GB的GP2 EBS，如果基于它建了个快照，再基于这个快照建个300GB的Volume，挂到机器里之后不做resize2fs或者xfs_growfs，在OS里我们对这个300GB磁盘的IOPS能提升吗？

c4.xlarge 4vCPU 7.5GiB RAM, root 20GiB, attached gp2 100GiB disk and io1 100GiB+600IOPS, we will create the gp2 volume snapshot to 300GB to see any performance increase

| Performance Metrics | C4.xlarge gp2 100GB | C4.xlarge gp2 300GB + filesystem extend | C4.xlarge io1 100GB + 600IOPS
| :------------------ | :------------------ | :------------------ | :------------------ | :------------------ |
| IOPS / Throughput (MBps) randwrite 16 KB I/O  | 3077 / 49.2 | 3074 / 49.2 | 615 / 9.8 |
| IOPS / Throughput (MBps) randread 16 KB I/O   | 7479 / 119 |  7517 / 120 | 6133 / 98
| IOPS / Throughput (MBps) randread/write 16 KB I/O | 2045/32.7 for read 2044/32.7 for write | 2047/32.7 for read 2048/32.7 for write | 541/8.6 for read 539/8.6 for write | 
| IOPS / Throughput (MBps) randwrite 4 KB I/O | 3063/12.2 | 3062/12.2 | 615/2.4 | 
| IOPS / Throughput (MBps) randread 4 KB I/O | 24959/99 | 24972/99.8 | 23589 / 94 | 
| IOPS / Throughput (MBps) randread/write 4 KB I/O | 2517/10 for read 2512/10 for write | 2510/10 for read 2511/10 for write | 594/2.3 for read 592/2.3 for write |
| IOPS / Throughput (MBps) randwrite 1 MB I/O |  89/92 | 89/92 | Not testing | 
| IOPS / Throughput (MBps) randread 1MB I/O | 146/143 | 145/142.5 | Not testing | 
| IOPS / Throughput (MBps) randread/write 1MB I/O |  76.5/74 for read 76.9/74 for write | " 6.5/74 for read 77.2/75 for write | Not testing | 

## Prepare
```bash
# Mount your EBS volume
[ec2-user@ip-10-0-0-38 ~]$ lsblk
NAME    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
xvda    202:0    0   20G  0 disk
└─xvda1 202:1    0   20G  0 part /
xvdb    202:16   0  100G  0 disk
xvdc    202:32   0  100G  0 disk
## install XFS file system support
[ec2-user@ip-10-0-0-38 ~]$ sudo yum install -y xfsprogs
```

## Create File system on EBS Volume
1. 100GB的gp2
```bash
[ec2-user@ip-10-0-0-38 ~]$ sudo file -s /dev/xvdb
/dev/xvdb: data

##use the mkfs -t command to create a file system on the volume
[ec2-user@ip-10-0-0-38 ~]$ sudo mkfs -t xfs /dev/xvdb
meta-data=/dev/xvdb              isize=512    agcount=4, agsize=6553600 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=1, sparse=0
data     =                       bsize=4096   blocks=26214400, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal log           bsize=4096   blocks=12800, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0

##mount the volume
[ec2-user@ip-10-0-0-38 ~]$ sudo mkdir -p /mnt/gp2_100G_data
[ec2-user@ip-10-0-0-38 ~]$ sudo mount /dev/xvdb /mnt/gp2_100G_data
```

2. 100GB的io1+600IOPS
```bash
[ec2-user@ip-10-0-0-38 ~]$ sudo file -s /dev/xvdc
/dev/xvdc: data

[ec2-user@ip-10-0-0-38 ~]$ sudo mkfs -t xfs /dev/xvdc
meta-data=/dev/xvdc              isize=512    agcount=4, agsize=6553600 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=1, sparse=0
data     =                       bsize=4096   blocks=26214400, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal log           bsize=4096   blocks=12800, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0

##mount the volume
[ec2-user@ip-10-0-0-38 ~]$ sudo mkdir -p /mnt/io1_100G_data
[ec2-user@ip-10-0-0-38 ~]$ sudo mount /dev/xvdc /mnt/io1_100G_data
```

3. Automatically Mount an Attached Volume After Reboot
```bash
[ec2-user@ip-10-0-0-38 ~]$ sudo lsblk
NAME    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
xvda    202:0    0   20G  0 disk
└─xvda1 202:1    0   20G  0 part /
xvdb    202:16   0  100G  0 disk /mnt/gp2_100G_data
xvdc    202:32   0  100G  0 disk /mnt/io1_100G_data
[ec2-user@ip-10-0-0-38 ~]$ df -h
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        3.7G     0  3.7G   0% /dev
tmpfs           3.7G     0  3.7G   0% /dev/shm
tmpfs           3.7G  488K  3.7G   1% /run
tmpfs           3.7G     0  3.7G   0% /sys/fs/cgroup
/dev/xvda1       20G  1.4G   19G   7% /
tmpfs           748M     0  748M   0% /run/user/1000
tmpfs           748M     0  748M   0% /run/user/0
/dev/xvdb       100G  135M  100G   1% /mnt/gp2_100G_data
/dev/xvdc       100G  135M  100G   1% /mnt/io1_100G_data

##Create a backup of your /etc/fstab file
sudo cp /etc/fstab /etc/fstab.orig

##Use the blkid command to find the UUID of the device.
[ec2-user@ip-10-0-0-38 ~]$ sudo blkid
/dev/xvda1: LABEL="/" UUID="8da1d979-c578-4cda-bf23-7bc195a79dd3" TYPE="xfs" PARTLABEL="Linux" PARTUUID="4bf447a2-06e0-4d45-b34f-c9d214730188"
/dev/xvdb: UUID="107764f2-dcce-4dfc-ad07-6e38f279f134" TYPE="xfs"
/dev/xvdc: UUID="c00358a2-90eb-4db5-a5bf-52aee6d82450" TYPE="xfs"

##Add the following entry to /etc/fstab to mount the device at the specified mount point.
sudo vim /etc/fstab
UUID=107764f2-dcce-4dfc-ad07-6e38f279f134 /mnt/gp2_100G_data xfs defaults,nofail 0 2
UUID=c00358a2-90eb-4db5-a5bf-52aee6d82450 /mnt/io1_100G_data xfs defaults,nofail 0 2
##To verify that your entry works
[ec2-user@ip-10-0-0-38 ~]$ sudo umount /mnt/gp2_100G_data && sudo umount /mnt/io1_100G_data
[ec2-user@ip-10-0-0-38 ~]$ sudo mount -a
[ec2-user@ip-10-0-0-38 ~]$ df -h
[ec2-user@ip-10-0-0-38 ~]$ sudo lsblk
```

# Run the testing
[c4.xlarge-gp2-io1-benchmark-100gp2](script/c4.xlarge-gp2-io1-benchmark-100gp2.md)

[c4.xlarge-gp2-io1-benchmark-300gp2snapshot](script/c4.xlarge-gp2-io1-benchmark-300gp2snapshot.md)

[c4.xlarge-gp2-io1-benchmark-100io1](script/c4.xlarge-gp2-io1-benchmark-100io1.md)